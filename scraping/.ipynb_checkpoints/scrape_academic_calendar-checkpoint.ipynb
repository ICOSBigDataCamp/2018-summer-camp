{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraper for UM academic calendar data\n",
    "\n",
    "@Author: [Jeff Lockhart](http://www-personal.umich.edu/~jwlock/)\n",
    "\n",
    "### Example URLs: \n",
    "\n",
    "- http://ro.umich.edu/calendar/ss17.php\n",
    "- http://ro.umich.edu/calendar/fa18.php\n",
    "- http://ro.umich.edu/calendar/wn10.php\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading one web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://ro.umich.edu/calendar/fa18.php\"\n",
    "r = requests.get(url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading many web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2003, 2019)\n",
    "list(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(years[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(years[0])[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = ['fa', 'wn']\n",
    "base_url = 'http://ro.umich.edu/calendar/'\n",
    "end_url = '.php'\n",
    "\n",
    "for y in years:\n",
    "    for t in terms:\n",
    "        url = base_url + t + str(y)[2:] + end_url\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = r.content\n",
    "\n",
    "#parse page with bs4\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select just the table of interest\n",
    "table = soup.find('table')\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select just the rows in the table\n",
    "rows = table.find_all('tr')\n",
    "rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = rows[0].find_all(['td'])\n",
    "cells[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a table from the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['event', 'times']\n",
    "data = []\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "for r in rows:\n",
    "    tmp = {}\n",
    "    for i, txt in enumerate(r.find_all('td')):\n",
    "        tmp[labels[i]] = txt.text\n",
    "        \n",
    "    data.append(tmp)\n",
    "    \n",
    "#convert our findings to a dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the text to dates\n",
    "- This particular text is messy, so getting dates is hard\n",
    "- We don't have time to go into `regular expressions` during the talk, but they are the solution.\n",
    "- The code below uses regular expressions to get the dates from the text.\n",
    "- Don't worry about how it works right now, just look to see that it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(txt, y):\n",
    "    date = None\n",
    "    m = re.search('^(\\w+\\s\\d+)', str(txt))\n",
    "    if m:\n",
    "        date = m.group(1)\n",
    "        date += ', '+str(y)\n",
    "        date = pd.to_datetime(date)\n",
    "    \n",
    "    return date\n",
    "\n",
    "df['date'] = df.times.apply(get_dates, y=y)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpful functions for selecting information out of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exam(txt):\n",
    "    txt = str(txt).lower()\n",
    "    result = 0\n",
    "    if 'exam' in txt:\n",
    "        result = 1\n",
    "    return result\n",
    "\n",
    "def class_start(txt):\n",
    "    txt = str(txt).lower()\n",
    "    result = 0\n",
    "    if 'classes' in txt:\n",
    "        if 'begin' in txt:\n",
    "            result = 1\n",
    "        elif 'resume' in txt:\n",
    "            result = 1\n",
    "    return result\n",
    "\n",
    "def class_stop(txt):\n",
    "    txt = str(txt).lower()\n",
    "    result = 0\n",
    "    if 'classes' in txt:\n",
    "        if 'end' in txt:\n",
    "            result = 1\n",
    "    elif 'recess' in txt:\n",
    "        result = 1\n",
    "    elif 'vacation' in txt:\n",
    "        if 'begin' in txt:\n",
    "            result = 1\n",
    "    return result\n",
    "\n",
    "def get_table(page, y):\n",
    "    #parse page with bs4\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    #select just the table of interest\n",
    "    table = soup.find('table')\n",
    "\n",
    "    labels = ['event', 'times']\n",
    "    data = []\n",
    "    rows = table.find_all('tr')\n",
    "    #each row is a game\n",
    "    for r in rows:\n",
    "        tmp = {}\n",
    "        \n",
    "        for i, txt in enumerate(r.find_all('td')):\n",
    "            tmp[labels[i]] = txt.text\n",
    "\n",
    "        data.append(tmp)\n",
    "    #convert our findings to a dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    \n",
    "    df['date'] = df.times.apply(get_dates, y=y)\n",
    "    df['exams'] = df.event.apply(exam)\n",
    "    df['class_start'] = df.event.apply(class_start)\n",
    "    df['class_stop'] = df.event.apply(class_stop)\n",
    "    \n",
    "    #drop the pesky null rows\n",
    "    df = df.dropna(axis=0, how='any')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "terms = ['fa', 'wn']\n",
    "years = range(2003, 2019)\n",
    "base_url = 'http://ro.umich.edu/calendar/'\n",
    "end_url = '.php'\n",
    "\n",
    "for y in years:\n",
    "    for t in terms:\n",
    "        #get the page for this term\n",
    "        url = base_url+t+str(y)[2:]+end_url\n",
    "        r = requests.get(url)\n",
    "\n",
    "        #if the page exists\n",
    "        if r.status_code == 200:\n",
    "            print('Processing', url)\n",
    "            tmp = get_table(r.content, y)\n",
    "            df = pd.concat([df, tmp])\n",
    "        else:\n",
    "            #some years don't have data. Ignore them and move on.\n",
    "            print('Error with', url)\n",
    "\n",
    "        #wait to be a polite lil spider\n",
    "        time.sleep(2)\n",
    "    \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring ang saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort our data and peak at it.\n",
    "df = df.sort_values(by='date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/UM_academic_calendar_no_summer.tsv', \n",
    "          sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting just one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.date.dt.year == 2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out when class is in session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for storing data\n",
    "data = []\n",
    "tmp = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in df.iterrows():\n",
    "    if r[1].class_start == 1:\n",
    "        data.append(tmp)\n",
    "        tmp = {}\n",
    "        tmp['class_start'] = r[1].date\n",
    "    elif r[1].class_stop == 1:\n",
    "        tmp['class_end'] = r[1].date\n",
    "        \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to dataframe\n",
    "classes = pd.DataFrame(data)\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns\n",
    "classes = classes[['class_start', 'class_end']]\n",
    "#drop empty rows\n",
    "classes = classes.dropna(axis=0)\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving results\n",
    "classes.to_csv('data/UM_class_periods_no_summer.tsv', \n",
    "          sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
