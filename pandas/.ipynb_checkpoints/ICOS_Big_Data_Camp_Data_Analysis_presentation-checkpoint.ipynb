{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 - Introduction to Python for Data Analysis\n",
    "# : Why you will NOT use Excel anymore!\n",
    "\n",
    "* **Instructor**: Ronnie (Saerom) Lee and Jeff Lockhart\n",
    "* **Date**: June 8th (Thursday), 2017\n",
    "* **Packages**: pandas, numpy, matplotlib, statsmodels\n",
    "    * *pandas*: an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "    \n",
    "    * *Matplotlib*: a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.\n",
    "    * *Statsmodels*: a Python module that provides classes and functions for the estimation of many different statistical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import relevant packages\n",
    "* *import* bring in packages of useful tools and functions for you to use\n",
    "* *import (package_name) as (abbreviation)* lets you refer to the package by the name abbreviation, so you can type less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# This makes it so that plots show up here in the notebook.\n",
    "# You do not need it if you are not using a notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. pandas\n",
    "\n",
    "### 1.1. How to create, save, and read a dataframe\n",
    "\n",
    "#### (1) Create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {'Course' : 'Intro to Big Data',\n",
    "        'Section' : '6', \n",
    "        'Names' : ['Ronnie', 'Jeff', 'Teddy', 'Jerry'],\n",
    "        'Group' : ['1', '2', '1', '2'],\n",
    "        'Year' : ['Junior'] * 2 + ['Senior'] * 2,\n",
    "        'Date' : pd.Timestamp('20160607'),\n",
    "        'Quiz' : np.array([20, 90, 60, 100], dtype='float64')}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Save the dataframe into a file: We will learn how to save first, since we don't have a file to read yet.\n",
    "* csv/tsv/txt file (Note: Don't forget to specify the separator!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', sep = ',', index = False) # if comma separated (csv)\n",
    "df.to_csv('data.tsv', sep = '\\t', index = False) # if tab separated (tsv)\n",
    "df.to_csv('data.txt', sep = '\\t', index = False) # you can also use sep = ',' as in csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('data.xlsx', index_label='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Read a file into a dataframe\n",
    "* csv/tsv/txt file (Note: Don't forget to specify the separator!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('data.csv', sep = ',')\n",
    "df_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tsv = pd.read_csv('data.tsv', sep = '\\t')\n",
    "df_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.ExcelFile('data.xlsx') as xlsx:\n",
    "    df_excel = pd.read_excel(xlsx, sheetname = 'Sheet1')\n",
    "df_excel\n",
    "\n",
    "### If there are multiple sheets to read from\n",
    "# with pd.ExcelFile('data.xlsx') as xlsx:\n",
    "#    df_sheet1 = pd.read_excel(xlsx, sheetname = 'Sheet1')\n",
    "#    df_sheet2 = pd.read_excel(xlsx, sheetname = 'Sheet2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Other formats you can read\n",
    "    - JSON strings: pd.read_json()\n",
    "    - HTML tables: pd.read_html()\n",
    "    - SQL databases: pd.read_sql_table()\n",
    "    - SAS files: pd.read_sas()\n",
    "    - Stata files: pd.read_stata()  \n",
    "    - and many more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. How to add and remove row/column(s) in the dateframe\n",
    "#### (1) Add row/column(s)\n",
    "* Rows using *.append()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, create a new dataframe\n",
    "new_data = {'Course' : 'Intro to Big Data',\n",
    "        'Section' : '6',\n",
    "        'Names' : ['The Donald', 'Melania'],\n",
    "        'Group' : '5',\n",
    "        'Year' : ['Freshman', 'Sophomore'],\n",
    "        'Date' : pd.Timestamp('20160607'),\n",
    "        'Quiz' : np.array([5, 85], dtype='float64')}\n",
    "\n",
    "df2 = pd.DataFrame(new_data)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append the new dataframe to the existing dataframe\n",
    "df = df.append(df2, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Or an alternative way to add row(s) is to use *pd.concat()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df2], axis = 0, ignore_index = True)    # If axis = 1, then add column\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Assignment'] = np.array([45, 85, 50, 90, 10, 70, 10, 70], dtype='float64')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Remove rows, columns, and duplicates\n",
    "* Rows (by index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Date', axis = 1)    \n",
    "# Note: axis = 1 denotes that we are referring to a column, not a row\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, in order to check whether there are any duplicates\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If there are duplicates, then run the following code\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Merge two dataframes\n",
    "* **Q.** Assume that the students were assigned to groups. For the term project, each group is required to do a presentation and submit a report. Suppose that you graded the presentations and the reports as the following. Create a dataframe with the following information:\n",
    "    - Group 1: \n",
    "        - Presentation: 80\n",
    "        - Report: 60\n",
    "    - Group 2:\n",
    "        - Presentation: 90\n",
    "        - Report: 80\n",
    "    - Group 3:\n",
    "        - Presentation: 100\n",
    "        - Report: 70\n",
    "    - Group 4:\n",
    "        - Presentation: 50\n",
    "        - Report: 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "term_project = {'Group' : ['1', '2', '3', '4'],\n",
    "                'Presentation': [80., 90., 100., 50.],\n",
    "                'Report' : np.array([60, 80, 70, 30], dtype='float64')}\n",
    "\n",
    "df3 = pd.DataFrame(term_project)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rather than putting in the scores one by one, we can simply *merge* the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df, df3, on = 'Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q.** OOPS! We lost The Donald and Melania! What went wrong?\n",
    "\n",
    "\n",
    "* **Q.** How should we merge the data in order to keep The Donald and Melania?\n",
    "    * Important parameter: how = {'left', 'right', 'outer', 'inner'}\n",
    "        - **inner** (*default*): use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys\n",
    "        - **outer**: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically\n",
    "        - **left**: use only keys from left frame, similar to a SQL left outer join; preserve key order\n",
    "        - **right**: use only keys from right frame, similar to a SQL right outer join; preserve key order\n",
    "    \n",
    "* **Q.** Which one of these should we set *how* as?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df, df3, how = 'left', on = 'Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q.** How would the dataframe look like if we set *how = right* or *how = outer*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df, df3, how = 'right', on = 'Group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df, df3, how = 'outer', on = 'Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Thus, the right way to merge the two dataframes is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, df3, how = 'left', on = 'Group')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Check what's in the dataframe\n",
    "#### (1) See the top and bottom rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nRows = 3    # The number of rows to show\n",
    "df.head(nRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail(nRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Display the index, columns, and the underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Sort by values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='Quiz')   # Ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='Quiz', ascending=False)    # Descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q.** What would happen if we sort a column which has a missing value (i.e., NaN)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by='Report', ascending=False)    # Descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Search for a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.where(df['Assignment'] > 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Names'].where(df['Assignment'] > 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q.** How can we count the number of students who got 'Assignment' higher than 50?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Names'].where(df['Assignment'] > 50).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) Select\n",
    "* Column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Assignment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Row(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[0,'Names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[0,['Assignment','Quiz']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['Assignment'] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df['Year'].isin(['Junior'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Missing data\n",
    "* Let's first take a look at what we have as our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Check whether there are any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.isnull(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the dataframe is large in dimension, it would be NOT be easy to see whether there are any 'True's\n",
    "    \n",
    "$\\rightarrow$ An easier way to check is to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) [Option 1] Drop row/column(s) with missing data\n",
    "* Drop row(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(how='any', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drop column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(how='any', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) [Option 2] Fill in missing values\n",
    "* Fill in ALL missing data with a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.fillna(value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fill in a single value by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[4,'Presentation'] = 30\n",
    "df.loc[5,'Presentation'] = 20\n",
    "df.loc[4,'Report'] = 60\n",
    "df.loc[5,'Report'] = 70\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Describe shows a quick statistic summary of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q.** EWW, IT'S UGLY WITH TOO MANY ZEROS! How can we make this more prettier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (2) Caculate\n",
    "* Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.median().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Min/Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Report'].min().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Report'].max().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.var().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Grouping: a process involving one or more of the following steps\n",
    "* Splitting the data into groups based on some criteria\n",
    "* Applying a function to each group independently\n",
    "* Combining the results into a data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('Group').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q.** How can we group by 'Group' and 'Year'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Group', 'Year']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='Report', index=['Year'], columns=['Group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Basic column operations\n",
    "* Logarithm\n",
    "    - Natural logarithm: np.log()\n",
    "    - The base 10 logarithm: np.log10()\n",
    "    - The base 2 logarithm: np.log2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['log_Report'] = np.log(df['Report'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sqrt_Report'] = np.sqrt(df['Report'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Q.** Suppose that the evaluation is based on the following weights\n",
    "    - Quiz: 15%\n",
    "    - Assignment: 20%\n",
    "    - Presentation: 25%\n",
    "    - Report: 40%\n",
    "\n",
    "How can we make a new column 'Total' which calculate the weighted sum and rank the students by 'Total' in descending order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Total'] = 0.15 * df['Quiz'] + 0.2 * df['Assignment'] + 0.25 * df['Presentation'] + 0.4 * df['Report']\n",
    "df.sort_values(by='Total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Application: Let's apply these tools to a set of real data\n",
    "#### Q. Read the datafile 'Salaries.csv' (separator = comma) as the variable 'salaries' and show its FIRST 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('./MLB/Salaries.csv', sep = ',')\n",
    "salaries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Read the datafile 'Batting.xlsx' (sheetname = 'Batting') as the variable 'batting' and show its LAST 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.ExcelFile('./MLB/Batting.xlsx') as xlsx:\n",
    "    batting = pd.read_excel(xlsx, sheetname = 'Batting')\n",
    "batting.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Create a variable 'data' by LEFT MERGING 'salaries' and 'batting' based on 'playerID',  'yearID', and  'teamID' and show the FIRST 7 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(salaries, batting, how='left', on = ['player', 'year', 'team'])\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Read the STATA datafile 'Pitching.dta' as the variable 'pitching' and show its LAST 4 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pitching  = pd.read_stata('./MLB/Pitching.dta')\n",
    "pitching.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. FOR SIMPLICITY, drop all columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pitching = pitching.dropna(how='any', axis = 1)\n",
    "pitching.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. LEFT MERGE 'data' and 'pitching' based on 'player', 'year', and 'team' and show the top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(data, pitching, how='left', on = ['player', 'year', 'team'])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Check whether there are any missing values in 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. FOR SIMPLICITY, fill in the missing values with zeros and re-check whether there are any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(value = 0.)\n",
    "pd.isnull(data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Read the csv files 'Basic.csv' (separator = comma) and INNER MERGE with 'data' based on 'player'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic = pd.read_csv('./MLB/Basic.csv', sep = ',')\n",
    "data = pd.merge(data, basic, how='inner', on = ['player'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Read the csv files 'Teams.csv' (separator = comma) and INNER MERGE with 'data' based on 'player'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teams = pd.read_csv('./MLB/Teams.csv', sep = ',')\n",
    "data = pd.merge(data, teams, how='left', on = ['team', 'year'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Save the dataframe 'data' as a tsv file, 'baseball.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('baseball.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Create a new column 'log_salary' by putting a natural log on ('salary' + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['log_salary'] = np.log(data['salary'] + 1)\n",
    "data.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Examine summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Examine statistics grouping by 'team' and show the FIRST 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.groupby('team').mean().round(2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Examine statistics grouping by 'team' AND 'year' and show the FIRST 20 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.groupby(['team', 'year']).mean().round(2).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. [TRY GOOGLING] Create dummy variables for 'year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_dummies = pd.get_dummies(data['year'],  drop_first = True)\n",
    "year_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Concatenate the two dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data, year_dummies], axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. matplotlib\n",
    "### 2.1. Let's plot this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Histogram: Histograms and other simple plots are easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['salary'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['log_salary'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Scatter plot: Basic two variable plots like this scatter are easy, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.plot.scatter(x = 'batting_RBI', \n",
    "                  y = 'salary',\n",
    "                  title = 'Scatter plot',\n",
    "                  figsize = (10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's get average salary by year born\n",
    "last = data[(data['year'] == 2014) & (data['birthYear'] > 1900)]\n",
    "tmp = last.groupby(by='birthYear').mean()\n",
    "\n",
    "#And make a line plot of it...\n",
    "tmp.plot.line(y='log_salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But what if we want to change the formatting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ax stands for \"axis\", we'll use this object to change more settings\n",
    "#we can also specify the image size, in inches, right here with the figsize argument\n",
    "ax = tmp.plot.line(y='log_salary', figsize=(10,8))\n",
    "\n",
    "#add a title to the chart\n",
    "ax.set_title('Average salary by year born')\n",
    "\n",
    "#label the axes\n",
    "ax.set_ylabel('log(salary)')\n",
    "ax.set_xlabel('Year born')\n",
    "\n",
    "#set the ticks so they're not half years\n",
    "#The range command makes a list of years starting in 1972 and counting by 2 up to (not including) 1993.\n",
    "ax.set_xticks(range(1972, 1993, 2))\n",
    "\n",
    "#show our plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#group our data by rank\n",
    "tmp = data.groupby(by='Rank').mean()\n",
    "\n",
    "#plot the mean log salary by rank\n",
    "ax = tmp['log_salary'].plot.bar(figsize=(10,8))\n",
    "ax.set_title('Average pay by rank')\n",
    "ax.set_ylabel('log(salary)')\n",
    "ax.set_xlabel('Rank')\n",
    "\n",
    "#set the upper and lower limits of the y axis\n",
    "ax.set_ylim(ymin=0, ymax=16)\n",
    "\n",
    "#get the location of the bars (rectangles)\n",
    "rects = ax.patches\n",
    "#loop throgh each bar and label it with its value\n",
    "for rect, label in zip(rects, tmp['log_salary']):\n",
    "    #find out the height of the bar on the image\n",
    "    height = rect.get_height()\n",
    "    l = '{:5.2f}'.format(label)\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 0.5, l, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bar chart with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the standard deviation instead of the mean when we group by rank\n",
    "tmp2 = data.groupby(by='Rank').std()\n",
    "#add the errors to out plotting call \n",
    "ax = tmp['log_salary'].plot.bar(yerr=tmp2['log_salary'], figsize=(10,8))\n",
    "ax.set_title('Average pay by rank')\n",
    "ax.set_ylabel('log(salery)')\n",
    "ax.set_xlabel('Rank')\n",
    "\n",
    "#set the upper and lower limits of the y axis\n",
    "ax.set_ylim(ymin=0, ymax=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make a boxplot of salaries, by rank\n",
    "ax = data.boxplot(column='log_salary', by='Rank', figsize=(10,8))\n",
    "ax.set_title('Pay by rank')\n",
    "ax.set_ylabel('log(salary)')\n",
    "ax.set_xlabel('Rank')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. FOR FUN: Now let's make it look like xkcd.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    data.log_salary.hist(bins=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    tmp = last.groupby(by='birthYear').mean()\n",
    "    ax = tmp.plot.line(y='log_salary', figsize=(10,8))\n",
    "    ax.set_title('Average salary, by year born')\n",
    "    ax.set_ylabel('log(salary)')\n",
    "    ax.set_xlabel('Year born')\n",
    "    ax.set_xticks(range(1972, 1993, 2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In fact, we can use many styles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "ax = tmp.plot.line(y='log_salary', figsize=(10,8))\n",
    "ax.set_title('Average salary, by year born')\n",
    "ax.set_ylabel('log(salary)')\n",
    "ax.set_xlabel('Year born')\n",
    "ax.set_xticks(range(1972, 1993, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "ax = tmp.plot.line(y='log_salary', figsize=(10,8))\n",
    "ax.set_title('Average salary, by year born')\n",
    "ax.set_ylabel('log(salary)')\n",
    "ax.set_xlabel('Year born')\n",
    "ax.set_xticks(range(1972, 1993, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('classic')\n",
    "ax = tmp.plot.line(y='log_salary', figsize=(10,8))\n",
    "ax.set_title('Average salary, by year born')\n",
    "ax.set_ylabel('log(salary)')\n",
    "ax.set_xlabel('Year born')\n",
    "ax.set_xticks(range(1972, 1993, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "ax = tmp.plot.line(y='log_salary', figsize=(10,8))\n",
    "ax.set_title('Average salary, by year born')\n",
    "ax.set_ylabel('log(salary)')\n",
    "ax.set_xlabel('Year born')\n",
    "ax.set_xticks(range(1972, 1993, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. statsmodels: Let's run regressions!\n",
    "\n",
    "* **Q.** (Linear regression) Let's see whether RBI and ERA explains log_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = 'log_salary ~ batting_RBI + ERA'\n",
    "result_ols = smf.ols(formula = formula, data = data).fit()\n",
    "print(result_ols.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* **Q.** (Logistic regression) Let's see whether RBI and ERA explains whether the player gets above-average log_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['above_average'] = (data['log_salary'] > data['log_salary'].mean()).astype(float)\n",
    "data['above_average'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = 'above_average ~ batting_RBI + ERA'\n",
    "result_logit = smf.logit(formula = formula, data = data).fit()\n",
    "print(result_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In statsmodels, there are many other methods and tools that you can use. For more information, click [here](http://www.statsmodels.org/stable/index.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
